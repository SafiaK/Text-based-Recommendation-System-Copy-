\section{Data Sets}
There is vast spectrum of domains that involve textual data;Books, news, academic journals, movies descriptions and tweet recommendations are most popular among them. There are a couple of data sets available for these domains,many researchers use them or generate their own data set or test their system online otherwise.
\subsection{ MSN News}
\cite{N11}  used MSN news logs to collect their data. Details of this dataset are as:
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of users & 10,000
\\
\hline
Total news & 42,255
\\
\hline 
Number of impressions & 445,230
\\
\hline 
Total number of samples & 7,141,584
\\
\hline
Average number of word per title & 11.29
\\
\hline 
Number of topic categories & 14
\\
\hline 
Total number of positive samples & 489,644
\\
\hline 
Total number of negative samples & 6,651,940
\\
\hline 
Duration in which data was collected & 12/13/2018 to 01/12/2019
\\
\hline
\end{tabular}

\caption{Details of dataset collected from MSN news logs}
\label{table:18}
\end{table}
\\
\subsection{AMiner collaboration dataset}
\cite{N65} used dataset that was extracted from \footnote{
http://arnetminer.org/collaboration}.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of authors & 1,436,990
\\
\hline
Number of publications & 1,932,442
\\
\hline 
Duration of data used in experiment & 1990-2005
\\
\hline 
Total sub-domain considered & 5
\\
\hline
Number of authors in Data mining sub-domain & 6,282
\\
\hline
Number of co-authors in Data mining sub-domain & 22,862
\\
\hline
Number of authors in Medical Informatics sub-domain & 9,150
\\
\hline
Number of co-authors in Medical Informatics sub-domain & 31,851
\\
\hline
Number of authors in Theory sub-domain & 5,449
\\
\hline
Number of co- authors in Theory sub-domain & 27,712
\\
\hline
Number of authors in Visualization sub-domain & 5,268
\\
\hline
Number of co- authors in Visualization sub-domain & 19,261
\\
\hline
Number of authors in Database sub-domain & 7,590
\\
\hline
Number of co- authors in Database sub-domain & 37,592
\\
\hline
\end{tabular}

\caption{Details of AMiner dataset}
\label{table:1}
\end{table}
\subsection{CheckinsJan Dataset}
\cite{N71} used CheckinsJan Dataset that has following properties.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Duration of data collection & January 2011-December 2011
\\
\hline
Number of users & 11326
\\
\hline 
Articles written in English & 71\%
\\
\hline 
Number of locat & 187218
\\
\hline
Number of citations in citations.csv & 7.95
\\
\hline
Number of papers in citations.csv & 572,895
\\
\hline
Average of references that each paper has & 14
\\
\hline
\end{tabular}

\caption{Details of CheckinsJan Dataset}
\label{table:2}
\end{table}
\\
\subsection{Docear’s recommender system}
\cite{N56} evaluated their system on Docear’s recommender  dataset described in \cite{Docear's}. It has four type of datasets, research papers, mind maps, user details and recommendations. Summaries of these four datasets is given in following tables.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of articles in paper.csv & 9.4M
\\
\hline
Number of articles that has URLs in paper.csv & 1.8M
\\
\hline 
Articles written in English & 71\%
\\
\hline 
Number of languages in articles & 5
\\
\hline
Number of citations in citations.csv & 7.95
\\
\hline
Number of papers in citations.csv & 572,895
\\
\hline
Average of references that each paper has & 14
\\
\hline
\end{tabular}

\caption{Details of research paper dataset in Docear's recommender}
\label{table:2}
\end{table}
\\


\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of articles in mindmaps.csv & 52,202
\\
\hline
Number of users who created mindmaps & 12,038
\\
\hline 
Number of revisions of mindmaps & 390,613
\\
\hline 
Number of mind-maps for which revision is available & 52,202
\\
\hline
Duration in which mind-maps were created & March 2012-March 2014
\\
\hline
Number of papers in mindmaps-papers.csv & 473,538
\\
\hline
Mind-maps that have links to PDF  & 24.8\%
\\
\hline
\end{tabular}

\caption{Details of Mind-maps dataset in Docear's recommender}
\label{table:3}
\end{table}

\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of registered users & 21,439
\\
\hline
Number of users registered every month & 1,000
\\
\hline 
Number of anonymous user-accounts created by spammers & 9,500
\\
\hline 
Number of registered users for which information is available in users.csv & 8,059
\\
\hline
Number of papers in users-papers.csv & 616,651
\\
\hline
Number of users in users-papers.csv & 6,726
\\
\hline
Number of cited documents per user & 9
\\
\hline
\end{tabular}

\caption{Details of Users dataset in Docear's recommender}
\label{table:4}
\end{table}



\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of recommendation set delivered by Docear in March 2012-2014 & 31,935
\\
\hline
Number of users to which recommendations delivered & 3,470
\\
\hline 
Number of recommendations delivered & 308,146
\\
\hline 
Number of unique documents & 147,135
\\
\hline
\end{tabular}

\caption{Details of recommedations dataset in Docear's recommender}
\label{table:5}
\end{table}
\subsection{DBbook dataset}
\cite{N28} used this dataset along movielens dataset. DBbook dataset is a part of Linked-Open Data-enabled Recommender Systems challenge and it is used for books recommendations.

\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of users& 5095
\\
\hline
Number of items & 2362
\\
\hline 
Total positive ratings & 57.11\%
\\
\hline 
Average of ratings & 14.53
\\
\hline 
Median of ratings & 14
\\
\hline 
Median of ratings & 10
\\
\hline
\end{tabular}

\caption{Summary statistics of DBbook dataset}
\label{table:6}
\end{table}
\subsection{Book-Crossing Dataset}
Book crossing data consists of book's data, crawled by\cite{bookcrossing} from book crossing website\footnote{https://www.bookcrossing.com}. The dataset is available online here\footnote{http://www2.informatik.uni-freiburg.de/~cziegler/BX/}. 
Dataset consists of three tables BX-Book-Ratings, BX-Users and BX-Books that contain 1, 157, 112 ratings, 278, 858 users and 271, 379 distinct ISBNs respectively. Following table contains the description of the type of information in these tables.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{2cm}|p{8cm}|}
\hline
Field name  & Description
\\
\hline
ISBN & Unique ID of a book
\\
\hline 
Book-Title & Like "Classical Mythology"
\\
\hline 
Book-Author & Name of the author
\\
\hline 
Year-Of-Publication & In which year a particular book was published
\\
\hline
Publisher & Information of publishing company
\\
\hline
Image & 3 pictures of book
\\
\hline
\end{tabular}

\caption{BX-Books}
\label{table:7}
\end{table}


\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{2cm}|p{8cm}|}
\hline
Field name  & Description
\\
\hline
User-ID & User ID in chronological order
\\
\hline 
Location & Home address of user that contains city and country information.
\\
\hline
Age & Age of a reader. It can be null.
\\
\hline
\end{tabular}

\caption{Fields of BX-Users table}
\label{table:8}
\end{table}


\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{2cm}|p{8cm}|}
\hline
Field name  & Description
\\
\hline
User-ID & ID of reader from BX-Users table
\\
\hline 
ISBN & ID of book from BX-Books
\\
\hline 
Book-Rating & Rating of a book given by a reader on the scale of 0-10
\\
\hline
\end{tabular}

\caption{Fields of  BX-Book-Ratings table}
\label{table:9}
\end{table}
\cite{N28}

\subsection{Adressa Dataset}
As described in \cite{Adressa}, Adressa dataset was created from Cxense platform to make news recommendation consumer intelligent using content analysis. It consists of news articles in Norwegian and has three versions, light version 1(1.4 GB) , light version 2(16 GB) and full version. Light version 1 and 2 are freely available at \footnote{http://reclab.idi.ntnu.no/dataset/} but full version is only granted after request. This dataset has 923 news articles and 2.7 million events. Following table contains structure of this dataset.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{2cm}|p{8cm}|}
\hline
Attributes & There are total 18 attributes in this dataset that describe each news event and how many views are associated with this event.
\\
\hline 
Author & Author name who has written a particular news
\\
\hline 
keywords & Specific keywords that better annotate article 
\\
\hline 
Entities & Important terms extracted from news article and has a description for label, count, type and weight.
\\
\hline
Body & Entire news article that is written in Norwegian
\\
\hline
\end{tabular}

\caption{Structure of Adressa dataset}
\label{table:4}
\end{table}
\\
There are 18 attributes of adressa compact dataset. Each event has a these attributes. Basically these are fields of this dataset. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{2cm}|p{8cm}|}
\hline
eventID & Integer value that uniquely identify each reading event.
\\
\hline 
Time & Unix time of each event
\\
\hline 
sessionStart & True if event is the first event in particular session otherwise False. 
\\
\hline
sessionStop & True if event is the last event in particular session otherwise False. 
\\
\hline 
activeTime & How much time a particular user spent on a page.
\\
\hline
canonicalURL & Visited page URL.
\\
\hline
referrerURL & Reference page URL
\\
\hline 
documentId & It is the internal ID of a page.
\\
\hline 
Title & Subject of the article
\\
\hline 
Category & a specific category to which the article belongs. For example sport category or music category.
\\
\hline
wordCount & Total number of words on a page
\\
\hline 
publishTime & Exact date and time the article was published.
\\
\hline 
userID & To identify cross-site users
\\
\hline
City & Each user's IP address has their demographic information so city name is inferred from there.
\\
\hline
Region & It is also extracted from user's demographic info stored in their IP.
\\
\hline 
Country & Country name of users.
\\
\hline 
os & Which operating system user has
\\
\hline 
deviceType & User's device type like desktop or cell phone. 
\\
\hline
\end{tabular}

\caption{Attribute description of Adressa}
\label{table:5}
\end{table}
\\
\cite{Adressa2} used SmartMedia Adressa dataset which is full version of this dataset and they used it for contextual hybrid session-based news recommendation.
\subsection{Globo.com Dataset}
This dataset is has 2 versions and publically available at \footnote{https://www.kaggle.com/gspmoreira/news-portal-user-interactions-by-globocom}. This dataset is used in \cite{N24} for recommending news using deep neural network. Dataset has 3 folders clicks.zip which contain user session, articles-metadata.csv for infomation of all articles and articles-embeddings.pickle folder which consists of a matrix that contain 250-dimensional embedding vectors for all articles.  Here is summary of 
dataset in following table.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Total number of unique users on Globo portal & 80M
\\
\hline 
New content per month & 100K
\\
\hline 
User-interaction period on news portal in which dataset is collected& 1 Oct- 16 Oct, 2017
\\
\hline 
Number of clicks & 3M
\\
\hline 
Total sessions &1.2M
\\
\hline 
Number of users who read news in specified time period of data gathering & 330,000
\\
\hline 
Total number of articles read in specified time period of data gathering & 50,000
\\
\hline
\end{tabular}

\caption{Description of Globo.com dataset}
\label{table:6}
\end{table}
\\
\subsection{Movielens Dataset}
This is most used dataset for movie recommendation purposes which is first released in 1998. The dataset is generated by grouplens \footnote{https://grouplens.org/} group. They have developed their own platform\footnote{https://movielens.org/} for movie recommendation. This group is actively doing research to improve their platform and keep on publishing their research related data sets on their website\footnote{https://grouplens.org/datasets/movielens/}, so there are quite a few flavours of movielens data set available. All the data sets are mainly consists of users, movies and ratings done by users against each movie. Following table presents the summary of all the types.
\\\cite{N28}

\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{3cm}|p{3cm}|p{1cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
Name  & Purpose & Date & no of movies & no of ratings & Tag applications & no of users
\\
\hline 
Movielens 25M dataset & For new research & 12-2019 & 27,000 &  20 M & 465,000 & 138,000
\\
\hline 
Movielens small dataset & For education and development & 9/2018 & 9,000 &  100,000 &  3,600 & 600
\\
\hline 
Movielens full dataset & For education and development & 9/2018 & 58,000 &  27,000,000 &  1,100,000 & 280,000
\\
\hline 
MovieLens 1B Dataset & Synthetic dataset & -- & -- &  20 M &  -- & --
\\
\hline 
Movielens 100k dataset & Very old. Stable benchmark & 4/1998 & 1700 &  100,000 &  -- & 1000 
\\
\hline 
MovieLens 1M Dataset & Old. Stable benchmark & 2/2003 & 4000  &  1 M &  -- & 6000 
\\
\hline 
MovieLens 10M Dataset & Old. Stable benchmark & 1/2009 & 10,000  &  10 M & 100,000 & 72,000 
\\
\hline 
MovieLens 20M Dataset & Old. Stable benchmark & 10/2016 & 27,000  &  20 M & 465,000 & 138,000
\\
\hline
\end{tabular}

\caption{Camparison of different types of movielens dataset}
\label{table:7}
\end{table}
As it is one of oldest dataset in recommendation system, a lot of research work have been done on this.\cite{N21} used 1M movielens dataset and match the each movie in this data set to the movie entity in TMDb movie knowledge graph using entity link method. \cite{N28} done their experiments on two datasets movielens and DBbook. Statistics proved that DBbook is more sparse in term of ratings and movielens is suitable for content-based user profiles. \cite{N31} carried their experiment using 1M movielens dataset to extract useful information such as director name, genre of movie and starring. The purpose of using 1M movielens dataset in \cite{N13} was to discover IMDb identifiers in this dataset utilizing Wikidata. \cite{N14} only required positive reviews from 1M movilens dataset so they removed ratings which were less than 3. After removing negative ratings from this dataset they have 5,883 users, 3,230 movies, and 226,101 ratings. \cite{N15} performed their experiments on movielens dataset which had 1,000,209 ratings of 3,883 movies given by 6,040 users. They removed users who has ratings for less than 20 movies and after filtering they had  0.9M ratings of 3,148 movies and total 5,886 users. \cite{N17} buil a different dataset IM-1M using 1M movielens dataset and  combining it with IMDB that contain movie information like genre, cast and director. After combining these two dataset there are total 6,040 users,  3,382 movies and 756,684 ratings.

\subsection{Worldnews on Raddit}
Reddit is a social network which divide topics into so called 'subreddits'. In subreddit 'worldnews', news of the whole world are published. This data is available on kaggle website\footnote{https://www.kaggle.com/rootuser/worldnews-on-reddit} used by \cite{N10}. This dataset consists of 8 columns described in following table.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{2cm}|p{8cm}|}
\hline
time\_created & A Unix timestamp when article was published on reddit.
\\
\hline 
date\_created & Date year-month-day when article was published.
\\
\hline 
up-votes & How many people approve this post. 
\\
\hline 
down-votes & How many people disapprove this post.
\\
\hline
title & Title of article.
\\
\hline
over-18 & Boolean value that shows if article is suited for certain age group.
\\
\hline 
Author & Reddit username of author.
\\
\hline 
subreddit & Its value is always Worldnews.
\\
\hline
\end{tabular}

\caption{Description of worldnews-on-Reddit dataset}
\label{table:8}
\end{table}
\subsection{SinaNews}
\cite{p4-8} collected data from Sina\footnote{http://news.sina.com.cn.} news website.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{6cm}|p{4cm}|}
\hline
Start Date & Aug 1, 2012
\\
\hline 
End Date &  Aug 31, 2012
\\
\hline 
Users & 1127 
\\
\hline 
 Total news articles & 28,737
\\
\hline
\end{tabular}

\caption{Description of SinaNews dataset}
\label{table:8}
\end{table}
\subsection{XMUNews}
\cite{p4-3} collected data from Xiamen University news reading website. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
Start Date & November
2004
\\
\hline 
End Date & February 2015
\\
\hline 
Number of ratings & 2,877,606
\\
\hline 
Number of news & 13,564
\\
\hline 
Total users & 163,627
\\
\hline 
Number of users after processing data& 4,149
\\
\hline 
Number of news after processing data & 2,761
\\
\hline 
Number of ratings after processing data & 180,540
\\
\hline
\end{tabular}

\caption{Description of XMUNews dataset}
\label{table:6}
\end{table}
\subsection{The examiner}
This data set contains click-bait headlines written by 21000+ authors over 6 years. It is not mandatory that it only contain click- bait headlines, but in general headlines of very low quality news articles. Dataset is publically available at kaggle\footnote{https://www.kaggle.com/therohk/examine-the-examiner}. \cite{N10} presented a personalized news recommender based at context analysis of news headlines and also used this dataset with Reuters and Reddit datasets. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
Total number of headlines & 3.09M Articles
\\
\hline 
Authors & 21,000
\\
\hline 
Duration & 6 years 
\\
\hline 
Start date & 2010-01-01
\\
\hline
End Date & 2015-21-31.
\\
\hline
Number of column & 2
\\
\hline 
Columns & publish\_date, headline\_text
\\
\hline
\end{tabular}

\caption{Description of examiner dataset}
\label{table:9}
\end{table}
\\
\subsection{Reuters Dataset}
This is a benchmark dataset that contain documents from Reuters newswire in 1987. There are multiple classes of documents in dataset and each document can belong to more than one class i.e multi-label. This datset is pulically available at \footnote{https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection}.  Martin Thoma has done some experiments on this dataset \footnote{https://martin-thoma.com/nlp-reuters/}.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
Total instances & 21578
\\
\hline 
Total Attributes & 5
\\
\hline 
Date Donated & 1997-09-26
\\
\hline 
Average word/document grouped by class & between 93 to 1263
\\
\hline
Total training documents & 7769 
\\
\hline
Total testing documents & 3019  
\\
\hline 
Total classes & 90
\\
\hline 
Vocabulary size of training data & 35247
\\
\hline
\end{tabular}

\caption{Summary of Reuters dataset}
\label{table:10}
\end{table}
\\
\subsection{Yelp Dataset}
It is the Yelp Challenge Dataset released by Yelp \footnote{http://www.yelp.com/} and is available now at Kaggle \footnote{https://www.kaggle.com/c/yelp-recsys-2013/data}. \cite{N17} used two datasets in their experiments Movielens and second is Yelp. Yelp contain checkins and local businesses and is much sparser than movielens IM-1M dataset. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{5cm}|p{3cm}|p{3cm}|}
\hline
  & Training set & Testing set
\\
\hline 
Businesses & 11,537 & 1,205
\\
\hline 
Checkin sets & 8,282 & 734
\\
\hline 
Users & 43,873 & 5,105
\\
\hline
Reviews & 229,907 & 22,956
\\
\hline
\end{tabular}

\caption{Summary statistics of standard Yelp dataset}
\label{table:11}
\end{table}
\\
As Yelp uses 5-star rating system \cite{N27} changed this two binary classes low(1,2,3) and high(4,5). 
\subsection{HotRec 2011 LastFM}
This dataset have social networking, tagging, and music artist listening information of 2K users from Last.fm online music system\footnote{ http://www.last.fm}. The data set is available on its website\footnote{http://ir.ii.uam.es/hetrec2011/datasets/lastfm/readme.txt}. Statistics of this dataset is shown in following table. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Total users & 1892 
\\
\hline 
Total artists & 17632  
\\
\hline 
bi-directional user friend relations & 12717 
\\
\hline 
average of friend relations per user & 13.443
\\
\hline
user-listened artist relations, i.e. tuples [user, artist, listeningCount] & 92834 
\\
\hline
average of artists most listened by each user & 49.067
\\
\hline 
tags & 11946
\\
\hline 
tag assignments (tas), i.e. tuples [user, tag, artist] & 186479 
\\
\hline 
average of tas per user & 98.562
\\
\hline 
average of tas per artist & 14.891
\\
\hline 
average of distinct tags used by each user & 18.930 
\\
\hline 
average of distinct tags used for each artist & 8.764 
\\
\hline
\end{tabular}

\caption{Statistics of HotRec 2011 LastFM dataset}
\label{table:12}
\end{table}
\\
In \cite{N13}, they used three dataset including  HotRec 2011 LastFM to retrieve reviews from IMDb, LibraryThing and Amazon of the items present in three datasets. 
\subsection{LibraryThing}
This dataset is used in \cite{N13} for recommending books. This dataset can be downloaded from \footnote{http://deepyeti.ucsd.edu/jmcauley/datasets/librarything/lthing\_data.tar.gz}.

\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Total users & 73,882
\\
\hline 
Total books & 337,561
\\
\hline 
Number of ratings/feedback & 979,053
\\
\hline 
Number of social relations & 120,536
\\
\hline
\end{tabular}

\caption{Statistics of LibraryThing dataset}
\label{table:12}
\end{table}

\subsection{Jester Dataset}
Jester dataset is a collaborative filtering dataset that contains ratings of jokes from users. This dataset is available at\footnote{http://eigentaste.berkeley.edu/dataset/}. It has three versions so far. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{3cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
  & Dataset 1 & Dataset 2 & Dataset 2+
\\
\hline 
ratings scale & -10 to +10 & -10 to +10 & -10 to +10
\\
\hline 
ratings & Over 4.1M & Over 1.7M & 1.7M + 500,000
\\
\hline 
jokes & 100 & 150 & 150
\\
\hline 
Users & 73,421 & 59,132 & 79,681
\\
\hline
Duration & April 1999 - May 2003 & November 2006 - May 2009 &  November 2006 - Nov 2012
\\
\hline
\end{tabular}

\caption{Summary statistics of different versions Jester dataset}
\label{table:13}
\end{table}
\\
\subsection{DBpedia}
DBpedia is a project to extract useful information from wikipedia and stored this information in knowledge graphs. DBpedia has released many datasets that are used in recommendation systems. 
The DBpedia 2016-04\footnote{https://wiki.dbpedia.org/downloads-2016-10} ontology has following properties.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
classes &760 
\\
\hline 
object properties & 1,105 
\\
\hline 
datatype properties & 1,622
\\
\hline 
specialised datatype properties  & 132 
\\
\hline 
owl:equivalentClass & 414 
\\
\hline
owl:equivalentProperty mappings external vocabularies & 220 
\\
\hline
Publication Year & 2017
\\
\hline
\end{tabular}

\caption{Details of DBpedia version 2016-10}
\label{table:14}
\end{table}
\\
\cite{N15} \cite{N13}
\\
\subsection{Wikidata}
Wikidata is a free knowledge base that have structured datasets from Wikipedia, Wikivoyage, Wiktionary, Wikisource, and others. Some statistics of Wikidata has shown in following table. Note that these are current statistics from \footnote{https://www.wikidata.org/wiki/Special:Statistics}.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
Content pages & 71,171,955 
\\
\hline 
Page edits since Wikidata was set up & 1,078,769,948
\\
\hline 
Average edits per page & 14.55
\\
\hline 
Registered users  & 3,829,127
\\
\hline 
Words in all content pages & 8,001,169,509
\\
\hline
\end{tabular}

\caption{Current statistics of Wikidata}
\label{table:14}
\end{table}
\\
\cite{N13}
\subsection{Plista}
Plista dataset is a part of ACM RecSys’13 Challenge which is a competition to build powerful news recommenders. This dataset consists of the million of user interactions with news portals. According to \cite{Plista}, it has four main data structures Create, Update, Impressions and Clicks.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{7cm}|p{3cm}|}
\hline
Duration of interaction capture & June 1 - 30, 2013
\\
\hline 
Total publishers & 13
\\
\hline 
Total IMPRESSIONS & 84,210,795
\\
\hline 
Average IMPRESSIONS  & 6,477,754
\\
\hline 
Total CLICKS & 1,095,323
\\
\hline
Average CLICKS & 84,256
\\
\hline
Total CREATES & 70,353 
\\
\hline
Average CREATES & 5,412
\\
\hline 
Total UPDATES & 5,174,116
\\
\hline 
Average UPDATES & 398,009
\\
\hline
\end{tabular}

\caption{Details of Plista dataset}
\label{table:14}
\end{table}
\\
\subsection{Twitter-News}
\cite{N61} conducted their research to analyze user modeling on Twitter and created their own dataset by crawling tweets of users. Some characteristics of this dataset are shown in following table.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of those users whose information streams were crawled & 20,000
\\
\hline 
Total tweets published by users & 10M
\\
\hline 
Number of monitored RSS feed & 60
\\
\hline 
Total news articles aggregated & 77,544
\\
\hline 
Tweets in final sample dataset & 2,316,204 
\\
\hline 
Users in final sample dataset & 1, 619
\\
\hline
\end{tabular}

\caption{Characteristics of Twitter-News dataset}
\label{table:14}
\end{table}
\\
\cite{N61} used this dataset in their work. Over miilon of tweets present in this dataset has URls to news articles and they used these URLs to find corresponding news articles. Total 63, 485 news articles were gathered and used for news recommendation. 
\subsection{Yahoo! Review Data}
 This is collection of datasets consist of movies, music and news articles released by Yahoo. It is available at \footnote{https://webscope.sandbox.yahoo.com/catalog.php?datatype=r}. \cite{Yahoo} used these two datasets to create  a advice giver recommender system. 
 \\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{2cm}|}
\hline 
Yahoo! Research Webscope Music review data & 1.8M users & 136,000 songs & 717M reviews & b/w 2002-2006
\\
\hline 
Yahoo! Research Webscope Movies review data &  7,642 users & 11,915 movies & 211,231 reviews & 
\\
\hline
\end{tabular}

\caption{Details of Yahoo! datasets}
\label{table:15}
\end{table}
\\
\subsection{Delicious Dataset}
\cite{N50} used bookmark dataset from deliouus \footnote{https://del.icio.us/} which is a social bookmarking site. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of those users & 1,000
\\
\hline 
Number of those items & 84,005
\\
\hline 
Number of tags & 42,324
\\
\hline 
Average of number of items per user & 95
\\
\hline 
Average of number of tags per user & 480
\\
\hline 
Average of number of tags/item (per user) & 5
\\
\hline 
Average of number of tags/item (by community) & 34
\\
\hline
\end{tabular}

\caption{Statistics of Delicious dataset}
\label{table:16}
\end{table}
\\
\subsection{Last.fm Dataset}
\cite{N50} also used music dataset from \footnote{http://www.last.fm/} website. Details of this dataset are as:
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of users & 1,000
\\
\hline 
Number of items & 50,202
\\
\hline 
Number of tags & 16,687
\\
\hline 
Average of number of items per user & 66
\\
\hline 
Average of number of tags per user & 149
\\
\hline 
Average of number of tags/item (per user) & 2
\\
\hline 
Average of number of tags/item (by community) & 49
\\
\hline
\end{tabular}

\caption{Statistics of Last.fm dataset}
\label{table:16}
\end{table}
\\
\subsection{Hermes News Portal (HNP) and Ceryx}
Ceryx is an extension of Hermes News Portal  and its core is OWL domain ontology\cite{CF-IDF+}. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of classes & 65
\\
\hline 
Number of object properties & 18
\\
\hline 
Number of data properties & 11
\\
\hline 
Total individulas & 1,167
\\
\hline
\end{tabular}

\caption{Details of OWL domain ontology}
\label{table:16}
\end{table}
\\
\subsection{Open-Corpus}
Open-Corpus\cite{N1} has computer science and neuro-science related articles that don't have full texts due to copyright issues.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8.1cm}|p{2.6cm}|}
\hline
no of documents & 6.9M
\\
\hline 
no of of unique authors & 8.3M
\\
\hline 
no of unique keyphrases & 823,677
\\
\hline 
avg. no of incoming citations & 7.4 ($\pm$ 38.1)
\\
\hline
avg. no of outgoing citations & 8.4 ($\pm$ 14.4)
\\
\hline
\end{tabular}
\caption{Characteristics of Open-Corpus dataset}
\label{table:23}

\end{table}
\\
\subsection{ProgrammableWeb}
\cite{N59}used data from ProgrammableWeb\footnote{https://www.programmableweb.com/} for useful Long-Tail web service recommendation. Data was crawled from June 2005 to June 2015. Here is the summary of their data set. Data is publicly available here \footnote{www.simflow.net/Team/baibing/DLTSR.rar}
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8.1cm}|p{2.6cm}|}
\hline
no of services & 12384
\\
\hline 
no of hot services & 329
\\
\hline 
no of long-tail services & 12055
\\
\hline 
no of mashups & 6288
\\
\hline
Vocabulary Size & 7500
\\
\hline 
average no of services in a of services in the mashups & 2.09
\\
\hline
Average no of word (term) tokens in the descriptions of mashups and services & 22.42
\\
\hline
\end{tabular}
\caption{Statistics of ProgrammableWeb dataset}
\label{table:23}

\end{table}
\\
\subsection{Bangali News}
\cite{N12} used Apache Nutch to crawl news data from 15 Bangali news papers. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of uncategorized news articles in corpus & 3,00,000
\\
\hline
Number of labeled news articles & 37,000
\\
\hline 
Number of catgories & 12
\\
\hline
\end{tabular}

\caption{Details of dataset collected from Bangali news papers}
\label{table:19}
\end{table}
\subsection{Others}
evaluation corpus is not openly accessible.
\cite{N5} used web crawler to extract computer science journals and articles from internet. They manually gathered root link of these papers and then using special extraction expressions further crawled links from these papers. Following table have some insight of this dataset. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of journals from which root links collected manually & 28 journals
\\
\hline
Number of conferences from which root links collected manually & 38 conferences
\\
\hline 
Duration of collected research paper that considered valid & 2014 and 2013
\\
\hline 
Total number of records for author, abstract and link of papers & 14,012
\\
\hline
\end{tabular}

%\caption{Insight of dataset created by \cite{N5}}
%\label{table:16}
\end{table}
\\
\cite{N9} conducted an experiment to collect dataset from undergraduate students. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of undergraduate students in this experiment & 10
\\
\hline
Type of data they provided & basic registration data
\\
\hline 
Number of comments published by these students & 20-30 (50-100 words)
\\
\hline 
Total number of clicked advertisements & 5-10
\\
\hline
\end{tabular}

%\caption{Details of experiment conducted by \cite{N9}}
%\label{table:17}
\end{table}
\\
After this experiment, they suggested 20 ads to each students and asked them to give their review whether these were according to their taste or not.
\\
Experiments conducted in \cite{N19} involve user clicks in the duration of April- June, 2013. This click data was collected from a large commercial search log in US. They removed entities of DBpedia that have less than 50 clicks and after preprocessing data has following statistics shown in table.  
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Number of sessions& 7M
\\
\hline
Number of users & 4M
\\
\hline 
Number of queries & 6M
\\
\hline 
Number of clicks & over 19M
\\
\hline
\end{tabular}

%\caption{Details of dataset used in \cite{N19}}
%\label{table:20}
\end{table}
\\
Dataset used in \cite{N62} comes from commercial news portal with million of users and articles. This dataset was collected in 6 months, first four months data was used as training data and last two months data was used as testing data. Users who have less than 20 clicks were removed from final data.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
Duration of data collection & 04/01/2014 to 09/30/2014
\\
\hline
Number of users & 64,669
\\
\hline 
Number of user-news click pairs for training & 26.5M
\\
\hline 
Number of user-news click pairs for testing & 13.3M
\\
\hline
\end{tabular}

%\caption{Details of dataset used in N62}
%\label{table:21}
\end{table}
\\
\cite{N20} collected total 7000 news events from Wikipedia Current Event Portal (WCEP).  For finding the ground truth of these news recommendation, total of 2000 events have used as queries at google to retrieve "people also search for" information from google knowledge base. 
\\
\cite{N22}  prepared journal data from different online publishing platforms like Elsevier, Springer, IEEE, ACM, and Inderscience. This data contain all information related to journals like their scope, name, keywords and tittle.
\\
Dataset used in \cite{N67} was collected from commercial news website. This dataset consisted of offline news and then they used an application for one month to test their system online. 
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{3cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
  Stage & Duration & \# of users & \# of news
\\
\hline 
offline & 6 months & 541,337 & 1,355,344
\\
\hline 
online & 1 month & 64,610 & 157,088
\\
\hline
\end{tabular}

%\caption{Statistics of N67 dataset}
%\label{table:22}
\end{table}
\\

\cite{N64} presented a cross domain user modeling in recommender systems using 4 datasets. First dataset was a collection of search engine quires from Bing Web vertical(User Feature), second was news articles from Bing News vertical(News feature). Third and fourth were app log data from Windows app store(App Feature) and Movie/TV show views(Movie/TV Features) from Xbox respectively. 
Statistics of these four dataset is shown in following table.
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{3cm}|p{3cm}|p{1.5cm}|p{1.5cm}|p{2cm}|}
\hline 
Type& Dataset & User Count & Feature Size & Joint Users
\\
\hline 
User View & Search & 20M & 3.5M & 
\\
\hline 
Item View & \makecell{News \\ Apps \\ Movie/TV}  & \makecell{5M \\ 1M \\ 60K} & \makecell{100K \\ 50K \\ 50K} & \makecell{1.5M \\ 210K \\ 16K}
\\
\hline
\end{tabular}

%\caption{Summary statistics of  datasets used in \cite{N64}}
%\label{table:24}
\end{table}
\\
\subsection{Overall Summary of well known Datasets}
\\
\begin{table}[!htbp] 
\centering
\footnotesize
\def\arraystretch{1.4}%
\centering
\begin{tabular}{|p{2cm}|p{3cm}|p{5cm}|}

\hline
\textbf{Data-set} & \textbf{Publicly Available} & \textbf{Studies }
\\
\hline
\end{tabular}

\caption{Comparison of popular datasets in recommender system}
\label{table:26}
\end{table}